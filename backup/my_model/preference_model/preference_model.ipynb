{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f66f3248-2fe7-4c23-b352-9ed584027783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    " \n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25e3a89-c318-4141-acab-a4fed98a659d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def exe_time(func):\n",
    "    '''\n",
    "    装饰器，返回原函数返回的，并打印出原函数前后的时间\n",
    "    '''\n",
    "    def new_func(*arg,**kwargs):\n",
    "        name=func.__name__\n",
    "        back=func(*args,**kwargs)\n",
    "        start=datetime.datetime.now()\n",
    "        end=datetime.datetime.now()\n",
    "        total=(end-start).total_seconds()\n",
    "        print('--{%s} start:@ %ss' % (name,start))\n",
    "        print('--{%s} end:@ %ss'%(name,end))\n",
    "        print('--{%s} total:@ %.3fs=%.3fh'%(name,total,total/3600.0))\n",
    "        return back\n",
    "    return new_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c1bdf7-9eea-47f1-82db-8a59677b12af",
   "metadata": {},
   "outputs": [],
   "source": [
    "##1定义MlP层\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,mlp_units,acti=torch.relu,size_x=216,rate=0.1):\n",
    "        super(MLP,self).__init__()\n",
    "        self.dropout=nn.Dropout(rate)\n",
    "        \n",
    "        self.layernorm1=nn.LayerNorm(mlp_units[0],eps=1e-6)\n",
    "        self.layernorm2=nn.LayerNorm(mlp_units[1],eps=1e-6)\n",
    "\n",
    "        self.dense1=nn.Linear(size_x,mlp_units[0])\n",
    "        self.dense2=nn.Linear(mlp_units[0],mlp_units[1])\n",
    "        self.dense_score=nn.Linear(mlp_units[1],mlp_units[2])\n",
    "        self.acti1=acti\n",
    "        self.acti2=torch.sigmoid\n",
    "    def forward(self,x):\n",
    "        x=self.dropout(x)\n",
    "        x=self.acti1(self.dense1(x))\n",
    "        x=self.layernorm1(x)\n",
    "        \n",
    "        x=self.dropout(x)\n",
    "        x=self.acti2(self.dense2(x))\n",
    "        x=self.layernorm2(x)\n",
    "\n",
    "        y=self.dense_score(x)\n",
    "        y=self.acti2(y)\n",
    "        y=torch.squeeze(y,dim=-1)\n",
    "\n",
    "        return y\n",
    "    def fun_obtain_params(self):\n",
    "        return [(name,param.shape) for name,param in self.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f6b0a53-d8b3-4aaf-99f8-04fabe87bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2测试MLP层\n",
    "# '''[256,128,1]是对embed维度的操作'''\n",
    "# model=MLP([256,128,1],acti=torch.relu,size_x=16,rate=0.1)\n",
    "# model.train()\n",
    "# a=time.time()\n",
    "# for _ in range(1000):\n",
    "#     user_emb=torch.tensor(np.random.uniform(size=(10,8)),\n",
    "#                           dtype=torch.float32)\n",
    "#     item_emb=torch.tensor(np.random.uniform(size=(10,8)),\n",
    "#                           dtype=torch.float32)\n",
    "#     embs=torch.cat((user_emb,item_emb),dim=1)\n",
    "#     preference=model(embs)\n",
    "# print(preference.shape,preference)\n",
    "# print('time cost',time.time()-a)\n",
    "# print('trainable_parameters:',model.fun_obtain_params())\n",
    "# print('l2 loss:',sum(p.pow(2).sum() for p in model.parameters()))\n",
    "# print('***mlp check:done')\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9268460-71ab-4575-a67b-d2ee2e562227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义注意力层\n",
    "class BahdanauAttentionQK_softmax(nn.Module):\n",
    "    def __init__(self,size_x,d_model,rate=0.0):\n",
    "        super(BahdanauAttentionQK_softmax,self).__init__()\n",
    "\n",
    "        self.wq=nn.Linear(size_x,d_model)\n",
    "        self.wk=nn.Linear(d_model,d_model)\n",
    "        self.v=nn.Linear(d_model,1)\n",
    "        self.dropout=nn.Dropout(rate)\n",
    "    def forward(self,q,k,mask=None):\n",
    "        '''\n",
    "        q:(bs,seqlen,dim=152)\n",
    "        k:(bs,seqlen,7,dim=64)\n",
    "        '''\n",
    "        q=self.dropout(q)\n",
    "        k=self.dropout(k)\n",
    "\n",
    "        query_with_time_axis=q.unsqueeze(2)\n",
    "        tiled_tensor=query_with_time_axis.repeat(1,1,7,1)#(bs,seq_len,7,152)\n",
    "        score=self.v(torch.tanh(self.wq(query_with_time_axis)\n",
    "                                +self.wk(k)))#(bs,seq_len,7,64) (bs,sl,7,64)\n",
    "        att_weights=torch.softmax(score,dim=-2)\n",
    "\n",
    "        att_out=att_weights*k\n",
    "        att_out=torch.sum(att_out,dim=-2)\n",
    "        \n",
    "        return att_out,att_weights#att_out注意力最后结果，att_weights注意力分数,(bs,sl,64),(bs,sl,7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c9c57c4-8ca2-46ea-a732-6c9bd584a3d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# attention_layer=BahdanauAttentionQK_softmax(8,10)\n",
    "# attention_layer.train()\n",
    "# #sample_hidden是q,（batch_size,seq_len);sample_output是k/v,(batch_size,k个数,seq_len)\n",
    "# sample_hidden=torch.tensor(np.random.random(size=(4,8)),dtype=torch.float32)\n",
    "# sample_output=torch.tensor(np.random.random(size=(4,5,8)),dtype=torch.float32)\n",
    "# att_result,att_weights=attention_layer(sample_hidden,sample_output)\n",
    "# print('att result shape:(batch_size,units){}'.format(att_result.shape))\n",
    "# print('att weights shape:(batch_size,sequence_length,1){}'\n",
    "#       .format(att_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c07e76-e11b-4044-8d70-c506dd74f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preference_Model(nn.Module):\n",
    "    def __init__(self,size_user,size_poi,size_cat_id,size_day,size_hour,size_hs5,\n",
    "                 size_embed_user,size_embed_poi,size_embed_cat,size_embed_day,size_embed_hour,size_embed_hs5,\n",
    "                 size_mlps,d_model,rate_mlp=0,rate_drop_preference=0.0):\n",
    "        '''\n",
    "        size_mlps:mlp层中的每层单元个数[256,128,1]\n",
    "        size_dense(d_model):256,模型中隐藏单元数量\n",
    "        '''\n",
    "        super(Preference_Model,self).__init__()\n",
    "\n",
    "        self.acti=torch.relu\n",
    "\n",
    "        self.embed_user=nn.Embedding(size_user,size_embed_user)\n",
    "        self.embed_poi=nn.Embedding(size_poi,size_embed_poi)\n",
    "        self.embed_cat_id=nn.Embedding(size_cat_id,size_embed_cat)\n",
    "        # self.embed_1st=nn.Embedding(size_1st,size_embed_1st)\n",
    "        self.embed_day=nn.Embedding(size_day,size_embed_day)\n",
    "        self.embed_hour=nn.Embedding(size_hour,size_embed_hour)\n",
    "        self.embed_hs5=nn.Embedding(size_hs5,size_embed_hs5)\n",
    "        \n",
    "        data_size=size_embed_poi+size_embed_cat+size_embed_day+size_embed_hour+size_embed_hs5\n",
    "        self.dense=nn.Linear(data_size,d_model)\n",
    "        self.model_att_qk_sft=BahdanauAttentionQK_softmax(data_size,d_model,rate_drop_preference)\n",
    "            # def __init__(self,mlp_units,acti=torch.relu,size_x=216,rate=0.1):\n",
    "        self.model_mlp=MLP(size_mlps)\n",
    "\n",
    "    def long_interest_att(self,embs_poi,embs_ctxt,sub_days_masks):\n",
    "        '''\n",
    "        sub_days_masks:(batch_size,seq_len,7)\n",
    "        '''\n",
    "        def divide_no_nan(x,y,nan_value=0.0):\n",
    "            mask=y==0\n",
    "            y=torch.where(mask,torch.ones_like(y),y)\n",
    "            result=x/y\n",
    "            result=torch.where(mask,torch.tensor(nan_value),result)\n",
    "            return result\n",
    "            \n",
    "        sub_days_masks=sub_days_masks.float()\n",
    "        cum_idxs=torch.cumsum(sub_days_masks,dim=1)\n",
    "        cum_idxs_mask=(cum_idxs==0.).float()\n",
    "        cum_idxs_mask=cum_idxs_mask.unsqueeze(-1)\n",
    "\n",
    "        input_embs=torch.cat([embs_poi,embs_ctxt],dim=2)#152\n",
    "        input_embs_expand=input_embs.unsqueeze(2)\n",
    "        input_subs_idxs=sub_days_masks.unsqueeze(3)\n",
    "        input_embs_expand_subs=input_embs_expand*input_subs_idxs\n",
    "\n",
    "        input_subs_idxs_cum=torch.cumsum(input_subs_idxs,dim=1)\n",
    "        input_embs_expand_subs_cum=torch.cumsum(input_embs_expand_subs,dim=1)\n",
    "        input_embs_expand_subs_cum_avg=divide_no_nan(input_embs_expand_subs_cum,input_subs_idxs_cum)\n",
    "\n",
    "        cum_subs_avg=input_embs_expand_subs_cum_avg#(b_s,seq_len,7,152)\n",
    "        cum_subs_msk=cum_idxs_mask#(bs,seq_len,7,1)\n",
    "        return cum_subs_avg,cum_subs_msk\n",
    "        \n",
    "    def forward(self,users,padded_pois,padded_cats_id,\n",
    "                lens,padded_days,padded_hours,padded_hs5s,padded_sub_days_masks):#,padded_subs_1st_masks):\n",
    "        embedded_users=self.embed_user(users)\n",
    "        embedded_pois=self.embed_poi(padded_pois)\n",
    "        embedded_cats_id=self.embed_cat_id(padded_cats_id)\n",
    "        # embedded_1st=self.embed_1st(padded_1st_cats_id)\n",
    "        embedded_days=self.embed_day(padded_days)\n",
    "        embedded_hour=self.embed_hour(padded_hours)\n",
    "        embedded_hs5s=self.embed_hs5(padded_hs5s)\n",
    "\n",
    "        embs_poi=torch.cat((embedded_pois,embedded_cats_id),axis=-1)#64+32=96,(bs,seq_len,dim)\n",
    "        embs_ctxt=torch.cat((embedded_days,embedded_hour,embedded_hs5s),axis=-1)#8+16+32=56\n",
    "        \n",
    "        #平均池化        \n",
    "        cum_subs_avg,cum_subs_msk=self.long_interest_att(embs_poi,embs_ctxt,padded_sub_days_masks)\n",
    "        #dense\n",
    "        cum_subs_avg=self.dense(cum_subs_avg)#(bs,seq_l,7,dim)\n",
    "        #att\n",
    "        ipt_q=torch.cat((embs_poi,embs_ctxt),dim=2)#正确的数据做q(bs,seq_len,dim=152)\n",
    "        k=cum_subs_avg#(bs,seq_len,7,dim=64)\n",
    "        \n",
    "        att_out,attw=self.model_att_qk_sft(ipt_q,k)\n",
    "\n",
    "        concat=torch.cat((att_out,ipt_q),dim=-1)#(bs,sq,64+152=216)\n",
    "        mlp_out=self.model_mlp(concat)\n",
    "        return (mlp_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc897374-7e69-4c0e-8eb6-a12c34e185e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#1加载数据\n",
    "#1.1加载Preference_Model初始化数据\n",
    "size_user=1084#长度1078，最大1083,又因为实际是从min=1,max=1083,编码min=0,max=1083,编码长度为1084\n",
    "size_poi=3906\n",
    "size_cat_id=285\n",
    "size_1st=9#用不到\n",
    "size_day=8\n",
    "size_hour=25\n",
    "size_hs5=95\n",
    "\n",
    "size_embed_user=64\n",
    "size_embed_poi=64\n",
    "size_embed_cat=32\n",
    "size_embed_1st=8\n",
    "size_embed_day=8\n",
    "size_embed_hour=16\n",
    "size_embed_hs5=32\n",
    "size_mlps=[256,128,1]\n",
    "d_model=64#即hidden_size\n",
    "\n",
    "batch_size=10\n",
    "epoch_size=20\n",
    "lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "822792e0-4632-4a0b-9e49-5b51d3e9d7f0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#1.2测试初始化model\n",
    "model=Preference_Model(size_user,size_poi,size_cat_id,size_day,size_hour,size_hs5,\n",
    "                       size_embed_user,size_embed_poi,size_embed_cat,size_embed_day,size_embed_hour,size_embed_hs5,\n",
    "                       size_mlps,d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c08fc23-9c24-4103-97ab-830f140a6aec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#2加载forward用的实际数据，一会放入dataloader中\n",
    "#2.1加载路径\n",
    "dir_users='/home/jovyan/datasets/tsmc_nyc_3_groupby_user_chronological/user_id.pkl'\n",
    "#用到所有数据，所以要计算所有数据的实际长度，最大长度，以及填充它们\n",
    "dir_padded_pois='/home/jovyan/datasets/tsmc_nyc_8_all_tgt_padding/padded_reindex_poi.pkl'\n",
    "dir_padded_cats_id='/home/jovyan/datasets/tsmc_nyc_8_all_tgt_padding/padded_reindex_cat_id.pkl'\n",
    "dir_lens='/home/jovyan/datasets/tsmc_nyc_8_all_tgt_padding/lens.pkl'\n",
    "dir_padded_days='/home/jovyan/datasets/tsmc_nyc_8_all_tgt_padding/padded_days.pkl'\n",
    "dir_padded_hours='/home/jovyan/datasets/tsmc_nyc_8_all_tgt_padding/padded_hours.pkl'\n",
    "dir_padded_hs5s='/home/jovyan/datasets/tsmc_nyc_8_all_tgt_padding/padded_hs5.pkl'\n",
    "#dir_padded_sub_days_masks用于做平均池化\n",
    "dir_padded_sub_days_masks='/home/jovyan/datasets/tsmc_nyc_8_all_tgt_padding/padded_subs_days.pkl'\n",
    "dir_padded_tgt='/home/jovyan/datasets/tsmc_nyc_8_all_tgt_padding/padded_tgt_reindex_poi.pkl'\n",
    "\n",
    "#2.2加载实际传入forward的数据\n",
    "# def forward(users,padded_pois,padded_cats_id,\n",
    "#                 lens,padded_days,padded_hours,padded_hs5s,padded_sub_days_masks):\n",
    "with open(dir_users,'rb') as f:\n",
    "    users=pickle.load(f)\n",
    "with open(dir_padded_pois,'rb') as f:\n",
    "    padded_pois=pickle.load(f)\n",
    "with open(dir_padded_cats_id,'rb') as f:\n",
    "    padded_cats_id=pickle.load(f)\n",
    "with open(dir_lens,'rb') as f:\n",
    "    lens=pickle.load(f)\n",
    "with open(dir_padded_days,'rb') as f:\n",
    "    padded_days=pickle.load(f)\n",
    "with open(dir_padded_hours,'rb') as f:\n",
    "    padded_hours=pickle.load(f)\n",
    "with open(dir_padded_hs5s,'rb') as f:\n",
    "    padded_hs5s=pickle.load(f)\n",
    "with open(dir_padded_sub_days_masks,'rb') as f:\n",
    "    padded_sub_days_masks=pickle.load(f)\n",
    "with open(dir_padded_tgt,'rb') as f:\n",
    "    padded_tgt=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9412588-877a-4d2d-9ad0-3500991e653f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#3写dataloader\n",
    "def Process_preference_model(users,padded_pois,padded_cats_id,padded_days,padded_hours,padded_hs5s,\n",
    "                             padded_sub_days_masks,\n",
    "                            tgt,batch_size):\n",
    "    class PreDataset(Dataset):\n",
    "        def __init__(self,users,padded_pois,padded_cats_id,padded_days,padded_hours,padded_hs5s,\n",
    "                     padded_sub_days_masks,tgt):\n",
    "            self.users=users\n",
    "            self.padded_pois=padded_pois\n",
    "            self.padded_cats_id=padded_cats_id\n",
    "            self.padded_days=padded_days\n",
    "            self.padded_hours=padded_hours\n",
    "            self.padded_hs5s=padded_hs5s\n",
    "            self.padded_sub_days_masks=padded_sub_days_masks\n",
    "            self.tgt=tgt\n",
    "        def __len__(self):\n",
    "            return len(self.users)\n",
    "        def __getitem__(self,index):\n",
    "            user=self.users[index]\n",
    "            poi=self.padded_pois[index]\n",
    "            cats_id=self.padded_cats_id[index]\n",
    "            days=self.padded_days[index]\n",
    "            hours=self.padded_hours[index]\n",
    "            hs5s=self.padded_hs5s[index]\n",
    "            sub_days_masks=self.padded_sub_days_masks[index]\n",
    "            tgt_item=self.tgt[index]\n",
    "            return user,poi,cats_id,days,hours,hs5s,sub_days_masks,tgt_item\n",
    "    #创建数据集实例\n",
    "    all_dataset=PreDataset(users,padded_pois,padded_cats_id,padded_days,padded_hours,padded_hs5s,padded_sub_days_masks,tgt)\n",
    "    dataloader=DataLoader(all_dataset,batch_size,shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e03caf64-a1d6-4bc3-8954-3204284f17be",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#3.1验证dataloader\n",
    "# def Process_preference_model(users,padded_pois,padded_cats_id,padded_days,padded_hours,padded_hs5s,\n",
    "#                              padded_sub_days_masks,\n",
    "#                             tgt,batch_size):\n",
    "pre_all_data=Process_preference_model(users,padded_pois,padded_cats_id,padded_days,padded_hours,padded_hs5s,\n",
    "                                      padded_sub_days_masks,padded_tgt,batch_size)\n",
    "# for batch_users,batch_poi,batch_cats,batch_days,batch_hours,batch_hs5s,batch_sub_days_masks,batch_tgt in pre_all_data:\n",
    "#     print(f'batch data:{batch_users},{batch_poi},{batch_cats},{batch_days},{batch_hours},{batch_hs5s},{batch_sub_days_masks},{batch_tgt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b3e61f9-6a7c-4217-aedf-a80d5817d59a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#2.3定义评价矩阵\n",
    "def Top_k_precision(indices, batch_y, k):\n",
    "    '''\n",
    "    indices:一个batch排序之后的下标，(batch_size,待预测长度),size_cat/size_poi，tensor\n",
    "    batch_y:(batch_size)\n",
    "    '''\n",
    "    precision = 0\n",
    "    for i in range(len(batch_y)):\n",
    "        if batch_y[i] in indices[:k]:\n",
    "            precision += 1\n",
    "    return precision / indices.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a304d72-5f53-44e0-8f74-89f4e168761b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "loss_function=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46775e6a-7486-431f-ac31-418c26593f5f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[0/20]\t loss:79665906.5625\t top@1:0.000000\t\n",
      "epoch:[1/20]\t loss:77521022.5000\t top@1:0.000000\t\n",
      "epoch:[2/20]\t loss:77426421.0000\t top@1:0.000000\t\n",
      "epoch:[3/20]\t loss:77331643.1250\t top@1:0.000000\t\n",
      "epoch:[4/20]\t loss:77365076.0625\t top@1:0.000000\t\n",
      "epoch:[5/20]\t loss:77388602.8125\t top@1:0.000000\t\n",
      "epoch:[6/20]\t loss:77345886.8438\t top@1:0.000000\t\n",
      "epoch:[7/20]\t loss:77337461.9375\t top@1:0.000000\t\n",
      "epoch:[8/20]\t loss:77377782.4062\t top@1:0.000000\t\n",
      "epoch:[9/20]\t loss:77393418.4375\t top@1:0.000000\t\n",
      "epoch:[10/20]\t loss:77321196.1250\t top@1:0.000000\t\n",
      "epoch:[11/20]\t loss:77333638.3125\t top@1:0.000000\t\n",
      "epoch:[12/20]\t loss:77347313.0000\t top@1:0.000000\t\n",
      "epoch:[13/20]\t loss:77323546.6250\t top@1:0.000000\t\n",
      "epoch:[14/20]\t loss:77334877.9688\t top@1:0.000000\t\n",
      "epoch:[15/20]\t loss:77307532.5625\t top@1:0.000000\t\n",
      "epoch:[16/20]\t loss:77332785.0000\t top@1:0.000000\t\n",
      "epoch:[17/20]\t loss:77290445.2188\t top@1:0.000000\t\n",
      "epoch:[18/20]\t loss:77312008.7500\t top@1:0.000000\t\n",
      "epoch:[19/20]\t loss:77306858.2500\t top@1:0.000000\t\n"
     ]
    }
   ],
   "source": [
    "#4将数据传入模型\n",
    "for epoch in range(epoch_size):\n",
    "    model.train()\n",
    "    epoch_loss=0.0\n",
    "    top_k_1=0\n",
    "    top_k_5=0\n",
    "    top_k_10=0\n",
    "    top_k_20=0\n",
    "    data_len=len(pre_all_data)\n",
    "    for batch_step,(batch_users,batch_poi,batch_cats,batch_days,batch_hours,\n",
    "                    batch_hs5s,batch_sub_days_masks,batch_tgt) in enumerate(pre_all_data):\n",
    "        model.zero_grad()\n",
    "        batch_users=batch_users\n",
    "        batch_poi=batch_poi\n",
    "        batch_cats=batch_cats\n",
    "        batch_days=batch_days\n",
    "        batch_hs5s=batch_hs5s\n",
    "        batch_sub_days_masks=batch_sub_days_masks\n",
    "        batch_tgt=batch_tgt\n",
    "        out=model(batch_users,batch_poi,batch_cats,lens,batch_days,batch_hours,batch_hs5s,batch_sub_days_masks)\n",
    "        loss=0.0\n",
    "        loss+=loss_function(out,torch.tensor(batch_tgt,dtype=torch.float))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss+=float(loss)\n",
    "        tgt_evaluation=[sliced_tensor[-1] for sliced_tensor in batch_tgt]\n",
    "        top_k_1+=Top_k_precision(out,tgt_evaluation,1)\n",
    "        # top_k_5+=Top_k_precision(indices,tgt_evaluation,5)\n",
    "        # top_k_10+=Top_k_precision(indices,tgt_evaluation,10)\n",
    "        # top_k_20+=Top_k_precision(indices,tgt_evaluation,20)\n",
    "    print('epoch:[{}/{}]\\t'.format(epoch,epoch_size),\n",
    "          'loss:{:.4f}\\t'.format(epoch_loss),\n",
    "        'top@1:{:4f}\\t'.format(top_k_1/data_len)\n",
    "        # 'top@5:{:4f}\\t'.format(top_k_5/data_len),\n",
    "        # 'top@10:{:4f}\\t'.format(top_k_10/data_len),\n",
    "        # 'top@20:{:4f}\\t'.format(top_k_20/data_len)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bde9836-b0f8-41e8-b53c-f6c6f8033933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
